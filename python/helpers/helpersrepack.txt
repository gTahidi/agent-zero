================================================================
Repopack Output File
================================================================

This file was generated by Repopack on: 2024-09-05T09:54:57.489Z

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This header section
2. Repository structure
3. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
1. This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
2. When processing this file, use the separators and "File:" markers to
  distinguish between different files in the repository.
3. Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.



For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
dirty_json.py
docker.py
duckduckgo_search.py
errors.py
extract_tools.py
files.py
messages.py
perplexity_search.py
print_style.py
rate_limiter.py
shell_local.py
shell_ssh.py
template_manager.py
templates.json
timed_input.py
tool.py
vdb.py
vector_db.py

================================================================
Repository Files
================================================================

================
File: dirty_json.py
================
class DirtyJson:
    def __init__(self):
        self._reset()

    def _reset(self):
        self.json_string = ""
        self.index = 0
        self.current_char = None
        self.result = None
        self.stack = []

    @staticmethod
    def parse_string(json_string):
        parser = DirtyJson()
        return parser.parse(json_string)
    
    def parse(self, json_string):
        self._reset()
        self.json_string = json_string
        self.index = self.index_of_first_brace(self.json_string) #skip any text up to the first brace
        self.current_char = self.json_string[self.index]
        self._parse()
        return self.result
        
    def feed(self, chunk):
        self.json_string += chunk
        if not self.current_char and self.json_string:
            self.current_char = self.json_string[0]
        self._parse()
        return self.result

    def _advance(self, count=1):
        self.index += count
        if self.index < len(self.json_string):
            self.current_char = self.json_string[self.index]
        else:
            self.current_char = None

    def _skip_whitespace(self):
        while self.current_char is not None and self.current_char.isspace():
            self._advance()

    def _parse(self):
        if self.result is None:
            self.result = self._parse_value()
        else:
            self._continue_parsing()

    def _continue_parsing(self):
        while self.current_char is not None:
            if isinstance(self.result, dict):
                self._parse_object_content()
            elif isinstance(self.result, list):
                self._parse_array_content()
            elif isinstance(self.result, str):
                self.result = self._parse_string()
            else:
                break

    def _parse_value(self):
        self._skip_whitespace()
        if self.current_char == '{':
            if self._peek(1) == '{':  # Handle {{
                self._advance(2)
            return self._parse_object()
        elif self.current_char == '[':
            return self._parse_array()
        elif self.current_char in ['"', "'", "`"]:
            if self._peek(2) == self.current_char * 2:  # type: ignore
                return self._parse_multiline_string()
            return self._parse_string()
        elif self.current_char and (self.current_char.isdigit() or self.current_char in ['-', '+']):
            return self._parse_number()
        elif self._match("true"):
            return True
        elif self._match('false'):
            return False
        elif self._match('null') or self._match("undefined"):
            return None
        elif self.current_char:
            return self._parse_unquoted_string()
        return None

    def _match(self, text: str) -> bool:
        cnt = len(text)
        if self._peek(cnt).lower() == text.lower():
            self._advance(cnt)
            return True
        return False
    
    def _parse_object(self):
        obj = {}
        self._advance()  # Skip opening brace
        self.stack.append(obj)
        self._parse_object_content()
        return obj

    def _parse_object_content(self):
        while self.current_char is not None:
            self._skip_whitespace()
            if self.current_char == '}':
                if self._peek(1) == '}':  # Handle }}
                    self._advance(2)
                else:
                    self._advance()
                self.stack.pop()
                return
            if self.current_char is None:
                self.stack.pop()
                return  # End of input reached while parsing object
            
            key = self._parse_key()
            value = None
            self._skip_whitespace()
            
            if self.current_char == ':':
                self._advance()
                value = self._parse_value()
            elif self.current_char is None:
                value = None  # End of input reached after key
            else:
                value = self._parse_value()
                
            self.stack[-1][key] = value
            
            self._skip_whitespace()
            if self.current_char == ',':
                self._advance()
                continue
            elif self.current_char != '}':
                if self.current_char is None:
                    self.stack.pop()
                    return  # End of input reached after value
                continue

    def _parse_key(self):
        self._skip_whitespace()
        if self.current_char in ['"', "'"]:
            return self._parse_string()
        else:
            return self._parse_unquoted_key()

    def _parse_unquoted_key(self):
        result = ""
        while self.current_char is not None and not self.current_char.isspace() and self.current_char not in [':', ',', '}', ']']:
            result += self.current_char
            self._advance()
        return result

    def _parse_array(self):
        arr = []
        self._advance()  # Skip opening bracket
        self.stack.append(arr)
        self._parse_array_content()
        return arr

    def _parse_array_content(self):
        while self.current_char is not None:
            self._skip_whitespace()
            if self.current_char == ']':
                self._advance()
                self.stack.pop()
                return
            value = self._parse_value()
            self.stack[-1].append(value)
            self._skip_whitespace()
            if self.current_char == ',':
                self._advance()
            elif self.current_char != ']':
                self.stack.pop()
                return

    def _parse_string(self):
        result = ""
        quote_char = self.current_char
        self._advance()  # Skip opening quote
        while self.current_char is not None and self.current_char != quote_char:
            if self.current_char == '\\':
                self._advance()
                if self.current_char in ['"', "'", '\\', '/', 'b', 'f', 'n', 'r', 't']:
                    result += {'b': '\b', 'f': '\f', 'n': '\n', 'r': '\r', 't': '\t'}.get(self.current_char, self.current_char)
                elif self.current_char == 'u':
                    unicode_char = ""
                    for _ in range(4):
                        if self.current_char is None:
                            return result
                        unicode_char += self.current_char
                        self._advance()
                    result += chr(int(unicode_char, 16))
                    continue
            else:
                result += self.current_char
            self._advance()
        if self.current_char == quote_char:
            self._advance()  # Skip closing quote
        return result

    def _parse_multiline_string(self):
        result = ""
        quote_char = self.current_char
        self._advance(3)  # Skip first quote
        while self.current_char is not None:
            if self.current_char == quote_char and self._peek(2) == quote_char * 2: # type: ignore
                self._advance(3)  # Skip first quote
                break
            result += self.current_char
            self._advance()
        return result.strip()

    def _parse_number(self):
        number_str = ""
        while self.current_char is not None and (self.current_char.isdigit() or self.current_char in ['-', '+', '.', 'e', 'E']):
            number_str += self.current_char
            self._advance()
        try:
            return int(number_str)
        except ValueError:
            return float(number_str)

    def _parse_true(self):
        self._advance()
        for char in 'rue':
            if self.current_char != char:
                return None
            self._advance()
        return True

    def _parse_false(self):
        self._advance()
        for char in 'alse':
            if self.current_char != char:
                return None
            self._advance()
        return False

    def _parse_null(self):
        self._advance()
        for char in 'ull':
            if self.current_char != char:
                return None
            self._advance()
        return None

    def _parse_unquoted_string(self):
        result = ""
        while self.current_char is not None and self.current_char not in [':', ',', '}', ']']:
            result += self.current_char
            self._advance()
        self._advance()
        return result.strip()

    def _peek(self, n):
        peek_index = self.index
        result = ''
        for _ in range(n):
            if peek_index < len(self.json_string):
                result += self.json_string[peek_index]
                peek_index += 1
            else:
                break
        return result

    def index_of_first_brace(self, input_str: str) -> int:
        return input_str.find("{")

================
File: docker.py
================
import time
import docker
import atexit
from typing import Dict, Optional
from python.helpers.files import get_abs_path
from python.helpers.errors import format_error
from python.helpers.print_style import PrintStyle

class DockerContainerManager:
    def __init__(self, image: str, name: str, ports: Optional[Dict[str, int]] = None, volumes: Optional[Dict[str, Dict[str, str]]] = None):
        """
        Initialize a DockerContainerManager.

        Args:
        - image (str): Name of the Docker image to use.
        - name (str): Name of the Docker container.
        - ports (Dict[str, int], optional): A dictionary of {host_port: container_port} to map ports from the container to the host. Defaults to None.
        - volumes (Dict[str, Dict[str, str]], optional): A dictionary of {host_path: {container_path: mode}} to mount volumes from the host to the container. Defaults to None.
        """
        self.image = image
        self.name = name
        self.ports = ports
        self.volumes = volumes
        self.client = self.init_docker()
        self.container = None

    def init_docker(self):
        """
        Initialize a Docker client.

        This method will retry indefinitely until a connection to Docker can be established.
        """
        while True:
            try:
                return docker.from_env()
            except Exception as e:
                err = format_error(e)
                if "ConnectionRefusedError(61," in err or "Error while fetching server API version" in err:
                    PrintStyle.hint("Connection to Docker failed. Is Docker running?")
                    PrintStyle.error(err)
                    time.sleep(5)
                else:
                    raise

    def start_container(self) -> None:
        """
        Start a Docker container.

        If a container with the given name already exists and is not running,
        start it. Otherwise, create a new container with the given image and
        name.

        Args:
        - None

        Returns:
        - None

        Raises:
        - None
        """
        existing_container = self.client.containers.list(filters={"name": self.name}, all=True)
        
        if existing_container:
            self.container = existing_container[0]
            if self.container.status != 'running':
                print(f"Starting existing container: {self.name} for safe code execution...")
                self.container.start()
            time.sleep(2)
        else:
            print(f"Initializing docker container {self.name} for safe code execution...")
            self.container = self.client.containers.run(
                self.image,
                detach=True,
                ports=self.ports,
                name=self.name,
                volumes=self.volumes,
            )
            atexit.register(self.cleanup_container)
            print(f"Started container with ID: {self.container.id}")
            time.sleep(5)

    def execute_command(self, command: str) -> str:
        """
        Execute a command in the Docker container.

        Args:
            command (str): The command to execute.

        Returns:
            str: The output of the command, or an error message if the command failed.

        Raises:
            Exception: If the Docker container is not initialized or started.
        """
        if not self.container:
            raise Exception("Docker container is not initialized or started")

        exec_result = self.container.exec_run(command, demux=True)
        exit_code, output = exec_result.exit_code, exec_result.output

        if exit_code == 0:
            stdout, stderr = output
            return stdout.decode('utf-8') if stdout else stderr.decode('utf-8') if stderr else "Command executed successfully, but produced no output."
        else:
            stdout, stderr = output
            error_message = stderr.decode('utf-8') if stderr else stdout.decode('utf-8') if stdout else "Unknown error occurred"
            return f"Error (exit code {exit_code}): {error_message}"

    def cleanup_container(self) -> None:
        """
        Clean up the Docker container.

        Stop and remove the container if it exists.

        Returns:
            None

        Raises:
            Exception: If the Docker container is not initialized or started.
        """
        if self.container:
            try:
                self.container.stop()
                self.container.remove()
                print(f"Stopped and removed the container: {self.container.id}")
            except Exception as e:
                print(f"Failed to stop and remove the container: {e}")

================
File: duckduckgo_search.py
================
from duckduckgo_search import DDGS

def search(query: str, results = 5, region = "wt-wt", time="y") -> list[str]:

    ddgs = DDGS()
    src = ddgs.text(
        query,
        region=region,  # Specify region 
        safesearch="off",  # SafeSearch setting
        timelimit=time,  # Time limit (y = past year)
        max_results=results  # Number of results to return
    )
    results = []
    for s in src:
        results.append(str(s))
    return results

================
File: errors.py
================
import re
import traceback

def format_error(e: Exception, max_entries=2):
    traceback_text = traceback.format_exc()
    # Split the traceback into lines
    lines = traceback_text.split('\n')
    
    # Find all "File" lines
    file_indices = [i for i, line in enumerate(lines) if line.strip().startswith("File ")]
    
    # If we found at least one "File" line, keep up to max_entries
    if file_indices:
        start_index = max(0, len(file_indices) - max_entries)
        trimmed_lines = lines[file_indices[start_index]:]
    else:
        # If no "File" lines found, just return the original traceback
        return traceback_text
    
    # Find the error message at the end
    error_message = ""
    for line in reversed(trimmed_lines):
        if re.match(r'\w+Error:', line):
            error_message = line
            break
    
    # Combine the trimmed traceback with the error message
    result = "Traceback (most recent call last):\n" + '\n'.join(trimmed_lines)
    if error_message:
        result += f"\n\n{error_message}"
    
    return result

================
File: extract_tools.py
================
import re, os
from typing import Any
from .  import files
# import dirtyjson
from .dirty_json import DirtyJson
import regex


def json_parse_dirty(json:str) -> dict[str,Any] | None:
    ext_json = extract_json_object_string(json)
    if ext_json:
        # ext_json = fix_json_string(ext_json)
        data = DirtyJson.parse_string(ext_json)
        if isinstance(data,dict): return data
    return None

def extract_json_object_string(content):
    start = content.find('{')
    if start == -1:
        return ""

    # Find the first '{'
    end = content.rfind('}')
    if end == -1:
        # If there's no closing '}', return from start to the end
        return content[start:]
    else:
        # If there's a closing '}', return the substring from start to end
        return content[start:end+1]

def extract_json_string(content):
    # Regular expression pattern to match a JSON object
    pattern = r'\{(?:[^{}]|(?R))*\}|\[(?:[^\[\]]|(?R))*\]|"(?:\\.|[^"\\])*"|true|false|null|-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?'
    
    # Search for the pattern in the content
    match = regex.search(pattern, content)
    
    if match:
        # Return the matched JSON string
        return match.group(0)
    else:
        print("No JSON content found.")
        return ""

def fix_json_string(json_string):
    # Function to replace unescaped line breaks within JSON string values
    def replace_unescaped_newlines(match):
        return match.group(0).replace('\n', '\\n')

    # Use regex to find string values and apply the replacement function
    fixed_string = re.sub(r'(?<=: ")(.*?)(?=")', replace_unescaped_newlines, json_string, flags=re.DOTALL)
    return fixed_string

================
File: files.py
================
import os, re, sys

def read_file(relative_path, **kwargs):
    absolute_path = get_abs_path(relative_path)  # Construct the absolute path to the target file

    with open(absolute_path) as f:
        content = remove_code_fences(f.read())

    # Replace placeholders with values from kwargs
    for key, value in kwargs.items():
        placeholder = "{{" + key + "}}"
        strval = str(value)
        # strval = strval.encode('unicode_escape').decode('utf-8')
        # content = re.sub(re.escape(placeholder), strval, content)
        content = content.replace(placeholder, strval)

    return content

def remove_code_fences(text):
    return re.sub(r'~~~\w*\n|~~~', '', text)

def get_abs_path(*relative_paths):
    return os.path.join(get_base_dir(), *relative_paths)

def exists(*relative_paths):
    path = get_abs_path(*relative_paths)
    return os.path.exists(path)


def get_base_dir():
    # Get the base directory from the current file path
    base_dir = os.path.dirname(os.path.abspath(os.path.join(__file__,"../../")))
    return base_dir

================
File: messages.py
================
from . import files


def truncate_text(output, threshold=1000):
    if len(output) <= threshold:
        return output

    # Adjust the file path as needed
    placeholder = files.read_file("./prompts/fw.msg_truncated.md", removed_chars=(len(output) - threshold))

    start_len = (threshold - len(placeholder)) // 2
    end_len = threshold - len(placeholder) - start_len

    truncated_output = output[:start_len] + placeholder + output[-end_len:]
    return truncated_output

================
File: perplexity_search.py
================
from openai import OpenAI
import models

def perplexity_search(query:str, model_name="llama-3.1-sonar-large-128k-online",api_key=None,base_url="https://api.perplexity.ai"):    
    api_key = api_key or models.get_api_key("perplexity")

    client = OpenAI(api_key=api_key, base_url=base_url)
        
    messages = [
    #It is recommended to use only single-turn conversations and avoid system prompts for the online LLMs (sonar-small-online and sonar-medium-online).
    
    # {
    #     "role": "system",
    #     "content": (
    #         "You are an artificial intelligence assistant and you need to "
    #         "engage in a helpful, detailed, polite conversation with a user."
    #     ),
    # },
    {
        "role": "user",
        "content": (
            query
        ),
    },
    ]
    
    response = client.chat.completions.create(
        model=model_name,
        messages=messages, # type: ignore
    )
    result = response.choices[0].message.content #only the text is returned
    return result

================
File: print_style.py
================
import os, webcolors, html
import sys
from datetime import datetime
from . import files
import streamlit as st

class PrintStyle:
    last_endline = True
    log_file_path = None

    def __init__(self,  bold=False, italic=False, underline=False, font_color="default", background_color="default", padding=False, log_only=False):
        self.bold = bold
        self.italic = italic
        self.underline = underline
        self.font_color = font_color
        self.background_color = background_color
        self.padding = padding
        self.padding_added = False  # Flag to track if padding was added
        self.log_only = log_only
        #self.kwargs = kwargs (Streamlit)

        if PrintStyle.log_file_path is None:
            logs_dir = files.get_abs_path("logs")
            os.makedirs(logs_dir, exist_ok=True)
            log_filename = datetime.now().strftime("log_%Y%m%d_%H%M%S.html")
            PrintStyle.log_file_path = os.path.join(logs_dir, log_filename)
            with open(PrintStyle.log_file_path, "w") as f:
                f.write("<html><body style='background-color:black;font-family: Arial, Helvetica, sans-serif;'><pre>\n")

    def _get_rgb_color_code(self, color, is_background=False):
        try:
            if color.startswith("#") and len(color) == 7:
                r = int(color[1:3], 16)
                g = int(color[3:5], 16)
                b = int(color[5:7], 16)
            else:
                rgb_color = webcolors.name_to_rgb(color)
                r, g, b = rgb_color.red, rgb_color.green, rgb_color.blue
            
            if is_background:
                return f"\033[48;2;{r};{g};{b}m", f"background-color: rgb({r}, {g}, {b});"
            else:
                return f"\033[38;2;{r};{g};{b}m", f"color: rgb({r}, {g}, {b});"
        except ValueError:
            return "", ""

    def _get_styled_text(self, text):
        start = ""
        end = "\033[0m"  # Reset ANSI code
        if self.bold:
            start += "\033[1m"
        if self.italic:
            start += "\033[3m"
        if self.underline:
            start += "\033[4m"
        font_color_code, _ = self._get_rgb_color_code(self.font_color)
        background_color_code, _ = self._get_rgb_color_code(self.background_color, True)
        start += font_color_code
        start += background_color_code
        return start + text + end

    def _get_html_styled_text(self, text):
        styles = []
        if self.bold:
            styles.append("font-weight: bold;")
        if self.italic:
            styles.append("font-style: italic;")
        if self.underline:
            styles.append("text-decoration: underline;")
        _, font_color_code = self._get_rgb_color_code(self.font_color)
        _, background_color_code = self._get_rgb_color_code(self.background_color, True)
        styles.append(font_color_code)
        styles.append(background_color_code)
        style_attr = " ".join(styles)
        escaped_text = html.escape(text).replace("\n", "<br>")  # Escape HTML special characters
        return f'<span style="{style_attr}">{escaped_text}</span>'

    def _add_padding_if_needed(self):
        if self.padding and not self.padding_added:
            if not self.log_only:
                print()  # Print an empty line for padding
            self._log_html("<br>")
            self.padding_added = True

    def _log_html(self, html):
        with open(PrintStyle.log_file_path, "a") as f: # type: ignore
            f.write(html)

    @staticmethod
    def _close_html_log():
        if PrintStyle.log_file_path:
            with open(PrintStyle.log_file_path, "a") as f:
                f.write("</pre></body></html>")            

    def get(self, *args, sep=' ', **kwargs):
        text = sep.join(map(str, args))
        return text, self._get_styled_text(text), self._get_html_styled_text(text)
        
    def print(self, *args, sep=' ', **kwargs):
        self._add_padding_if_needed()
        if not PrintStyle.last_endline: 
            print()
            self._log_html("<br>")
        plain_text, styled_text, html_text = self.get(*args, sep=sep, **kwargs)
        if not self.log_only:
            print(styled_text, end='\n', flush=True)
        self._log_html(html_text+"<br>\n")
        PrintStyle.last_endline = True
        #st.session_state.logs.append(text) (Streamlit)

    def stream(self, *args, sep=' ', **kwargs):
        self._add_padding_if_needed()
        plain_text, styled_text, html_text = self.get(*args, sep=sep, **kwargs)
        if not self.log_only:
            print(styled_text, end='', flush=True)
        self._log_html(html_text)
        PrintStyle.last_endline = False
        #st.session_state.logs.append(text) (Streamlit)

    def is_last_line_empty(self):
        lines = sys.stdin.readlines()
        return bool(lines) and not lines[-1].strip()

    @staticmethod
    def hint(text:str):
        PrintStyle(font_color="#6C3483", padding=True).print("Hint: "+text)

    @staticmethod
    def error(text:str):
        PrintStyle(font_color="red", padding=True).print("Error: "+text)

# Ensure HTML file is closed properly when the program exits
import atexit
atexit.register(PrintStyle._close_html_log)

================
File: rate_limiter.py
================
import time
from collections import deque
from dataclasses import dataclass
from typing import List, Tuple
from .print_style import PrintStyle

@dataclass
class CallRecord:
    timestamp: float
    input_tokens: int
    output_tokens: int = 0  # Default to 0, will be set separately

class RateLimiter:
    def __init__(self, max_calls: int, max_input_tokens: int, max_output_tokens: int, window_seconds: int = 60):
        self.max_calls = max_calls
        self.max_input_tokens = max_input_tokens
        self.max_output_tokens = max_output_tokens
        self.window_seconds = window_seconds
        self.call_records: deque = deque()

    def _clean_old_records(self, current_time: float):
        while self.call_records and current_time - self.call_records[0].timestamp > self.window_seconds:
            self.call_records.popleft()

    def _get_counts(self) -> Tuple[int, int, int]:
        calls = len(self.call_records)
        input_tokens = sum(record.input_tokens for record in self.call_records)
        output_tokens = sum(record.output_tokens for record in self.call_records)
        return calls, input_tokens, output_tokens

    def _wait_if_needed(self, current_time: float, new_input_tokens: int):
        while True:
            self._clean_old_records(current_time)
            calls, input_tokens, output_tokens = self._get_counts()
            
            wait_reasons = []
            if self.max_calls > 0 and calls >= self.max_calls:
                wait_reasons.append("max calls")
            if self.max_input_tokens > 0 and input_tokens + new_input_tokens > self.max_input_tokens:
                wait_reasons.append("max input tokens")
            if self.max_output_tokens > 0 and output_tokens >= self.max_output_tokens:
                wait_reasons.append("max output tokens")
            
            if not wait_reasons:
                break
            
            oldest_record = self.call_records[0]
            wait_time = oldest_record.timestamp + self.window_seconds - current_time
            if wait_time > 0:
                PrintStyle(font_color="yellow", padding=True).print(f"Rate limit exceeded. Waiting for {wait_time:.2f} seconds due to: {', '.join(wait_reasons)}")
                time.sleep(wait_time)
            current_time = time.time()

    def limit_call_and_input(self, input_token_count: int) -> CallRecord:
        current_time = time.time()
        self._wait_if_needed(current_time, input_token_count)
        new_record = CallRecord(current_time, input_token_count)
        self.call_records.append(new_record)
        return new_record

    def set_output_tokens(self, output_token_count: int):
        if self.call_records:
            self.call_records[-1].output_tokens += output_token_count
        return self

# Example usage
rate_limiter = RateLimiter(max_calls=5, max_input_tokens=1000, max_output_tokens=2000)

def rate_limited_function(input_token_count: int, output_token_count: int):
    # First, limit the call and input tokens (this may wait)
    rate_limiter.limit_call_and_input(input_token_count)
    
    # Your function logic here
    print(f"Function called with {input_token_count} input tokens")
    
    # After processing, set the output tokens (this doesn't wait)
    rate_limiter.set_output_tokens(output_token_count)
    print(f"Function completed with {output_token_count} output tokens")

================
File: shell_local.py
================
# import select
# import subprocess
# import time
# import sys
# from typing import Optional, Tuple

# class LocalInteractiveSession:
#     def __init__(self):
#         self.process = None
#         self.full_output = ''

#     def connect(self):
#         # Start a new subprocess with the appropriate shell for the OS
#         if sys.platform.startswith('win'):
#             # Windows
#             self.process = subprocess.Popen(
#                 ['cmd.exe'],
#                 stdin=subprocess.PIPE,
#                 stdout=subprocess.PIPE,
#                 stderr=subprocess.PIPE,
#                 text=True,
#                 bufsize=1
#             )
#         else:
#             # macOS and Linux
#             self.process = subprocess.Popen(
#                 ['/bin/bash'],
#                 stdin=subprocess.PIPE,
#                 stdout=subprocess.PIPE,
#                 stderr=subprocess.PIPE,
#                 text=True,
#                 bufsize=1
#             )

#     def close(self):
#         if self.process:
#             self.process.terminate()
#             self.process.wait()

#     def send_command(self, command: str):
#         if not self.process:
#             raise Exception("Shell not connected")
#         self.full_output = ""
#         self.process.stdin.write(command + '\n') # type: ignore
#         self.process.stdin.flush() # type: ignore
 
#     def read_output(self) -> Tuple[str, Optional[str]]:
#         if not self.process:
#             raise Exception("Shell not connected")

#         partial_output = ''
#         while True:
#             rlist, _, _ = select.select([self.process.stdout], [], [], 0.1)
#             if rlist:
#                 line = self.process.stdout.readline()  # type: ignore
#                 if line:
#                     partial_output += line
#                     self.full_output += line
#                     time.sleep(0.1)
#                 else:
#                     break  # No more output
#             else:
#                 break  # No data available

#         if not partial_output:
#             return self.full_output, None
        
#         return self.full_output, partial_output

================
File: shell_ssh.py
================
# import paramiko
# import time
# import re
# from typing import Optional, Tuple

# class SSHInteractiveSession:

#     end_comment = "# @@==>> SSHInteractiveSession End-of-Command  <<==@@"

#     ps1_label = "SSHInteractiveSession CLI>"
    
#     def __init__(self, hostname: str, port: int, username: str, password: str):
#         self.hostname = hostname
#         self.port = port
#         self.username = username
#         self.password = password
#         self.client = paramiko.SSHClient()
#         self.client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
#         self.shell = None
#         self.full_output = b''

#     def connect(self):
#         # try 3 times with wait and then except
#         errors = 0
#         while True:
#             try:
#                 self.client.connect(self.hostname, self.port, self.username, self.password)
#                 self.shell = self.client.invoke_shell(width=160,height=48)
#                 # self.shell.send(f'PS1="{SSHInteractiveSession.ps1_label}"'.encode())
#                 return
#                 # while True: # wait for end of initial output
#                 #     full, part = self.read_output()
#                 #     if full and not part: return
#                 #     time.sleep(0.1)
#             except Exception as e:
#                 errors += 1
#                 if errors < 3:
#                     print(f"SSH Connection attempt {errors}...")
#                     time.sleep(5)
#                 else:
#                     raise e

#     def close(self):
#         if self.shell:
#             self.shell.close()
#         if self.client:
#             self.client.close()

#     def send_command(self, command: str):
#         if not self.shell:
#             raise Exception("Shell not connected")
#         self.full_output = b""
#         self.shell.send((command + " \\\n" +SSHInteractiveSession.end_comment + "\n").encode())

#     def read_output(self) -> Tuple[str, str]:
#         if not self.shell:
#             raise Exception("Shell not connected")

#         partial_output = b''
#         while self.shell.recv_ready():
#             data = self.shell.recv(1024)
#             partial_output += data
#             self.full_output += data
#             time.sleep(0.1)  # Prevent busy waiting

#         # Decode once at the end
#         decoded_partial_output = partial_output.decode('utf-8', errors='replace')
#         decoded_full_output = self.full_output.decode('utf-8', errors='replace')
        
#         decoded_partial_output = self.clean_string(decoded_partial_output)
#         decoded_full_output = self.clean_string(decoded_full_output)

#         # Split output at end_comment
#         if SSHInteractiveSession.end_comment in decoded_full_output:
#             decoded_full_output = decoded_full_output.split(SSHInteractiveSession.end_comment)[-1].lstrip("\r\n")
#             decoded_partial_output = decoded_partial_output.split(SSHInteractiveSession.end_comment)[-1].lstrip("\r\n")
        
#         return decoded_full_output, decoded_partial_output


#     def clean_string(self, input_string):
#         # Remove ANSI escape codes
#         ansi_escape = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
#         cleaned = ansi_escape.sub('', input_string)
        
#         # Replace '\r\n' with '\n'
#         cleaned = cleaned.replace('\r\n', '\n')
        
#         return cleaned

================
File: template_manager.py
================
import streamlit as st
import json
import os
from streamlit_card import card
import uuid

class Template:
    def __init__(self, id, name, url, navigation_goal, data_extraction_goal, advanced_settings=None):
        self.id = id
        self.name = name
        self.url = url
        self.navigation_goal = navigation_goal
        self.data_extraction_goal = data_extraction_goal
        self.advanced_settings = advanced_settings or {}

    def to_dict(self):
        return {
            "id": self.id,
            "name": self.name,
            "url": self.url,
            "navigation_goal": self.navigation_goal,
            "data_extraction_goal": self.data_extraction_goal,
            "advanced_settings": self.advanced_settings
        }

    @classmethod
    def from_dict(cls, data):
        return cls(
            id=data.get("id", str(uuid.uuid4())),
            name=data["name"],
            url=data["url"],
            navigation_goal=data["navigation_goal"],
            data_extraction_goal=data["data_extraction_goal"],
            advanced_settings=data.get("advanced_settings", {})
        )

def get_templates_file_path():
    return os.path.join(os.path.dirname(os.path.abspath(__file__)), 'templates.json')

def truncate_text(text, max_length):
    return text[:max_length] + '...' if len(text) > max_length else text

def load_templates():
    template_file = get_templates_file_path()
    if not os.path.exists(template_file):
        return []
    
    try:
        with open(template_file, 'r') as f:
            data = json.load(f)
            return [Template.from_dict(item) for item in data]
    except json.JSONDecodeError:
        st.error(f"Error decoding {template_file}. Starting with empty templates.")
        return []
    except Exception as e:
        st.error(f"Unexpected error loading templates: {str(e)}")
        return []

def save_templates(templates):
    template_file = get_templates_file_path()
    with open(template_file, 'w') as f:
        json.dump([template.to_dict() for template in templates], f, indent=2)

def templates_page():
    st.title("Template Manager")

    if 'templates' not in st.session_state:
        st.session_state.templates = load_templates()

    # Add New Template button
    col1, col2 = st.columns([3, 1])
    with col2:
        if st.button("➕ Add New Template", key="add_new_template"):
            st.session_state.show_new_template_form = True

    # New Template Form
    if st.session_state.get('show_new_template_form', False):
        with st.form("new_template_form"):
            new_template_name = st.text_input("Template Name")
            new_template_url = st.text_input("URL")
            new_template_navigation_goal = st.text_area("Navigation Goal")
            new_template_data_extraction_goal = st.text_area("Data Extraction Goal")
            
            with st.expander("Advanced Settings"):
                advanced_settings = {}
                advanced_settings['custom_field'] = st.text_input("Custom Field")

            submitted = st.form_submit_button("Save Template")
            
            if submitted and new_template_name and new_template_url and new_template_navigation_goal and new_template_data_extraction_goal:
                new_template = Template(
                    id=str(uuid.uuid4()),
                    name=new_template_name,
                    url=new_template_url,
                    navigation_goal=new_template_navigation_goal,
                    data_extraction_goal=new_template_data_extraction_goal,
                    advanced_settings=advanced_settings
                )
                st.session_state.templates.append(new_template)
                save_templates(st.session_state.templates)
                st.session_state.show_new_template_form = False
                st.success("Template saved successfully!")
                st.rerun()

    # Display existing templates
    st.subheader("Available Templates")
    cols = st.columns(3)
    for idx, template in enumerate(st.session_state.templates):
        with cols[idx % 3]:
            card_content = f"""
            **URL:** {truncate_text(template.url, 30)}
            **Navigation Goal:** {truncate_text(template.navigation_goal, 50)}
            **Data Extraction Goal:** {truncate_text(template.data_extraction_goal, 50)}
            """
            card(
                title=template.name,
                text=card_content,
                key=f"card_{template.id}",
                on_click=lambda t=template: st.session_state.update({"use_template": t.id})
            )
            # Add edit button separately
            if st.button("✏️ Edit", key=f"edit_{template.id}"):
                st.session_state.edit_template = template.id


    # Handle edit template
    if 'edit_template' in st.session_state:
        template = next((t for t in st.session_state.templates if t.id == st.session_state.edit_template), None)
        if template:
            st.subheader(f"Edit Template: {template.name}")
            with st.form("edit_template_form"):
                edited_name = st.text_input("Template Name", value=template.name)
                edited_url = st.text_input("URL", value=template.url)
                edited_navigation_goal = st.text_area("Navigation Goal", value=template.navigation_goal)
                edited_data_extraction_goal = st.text_area("Data Extraction Goal", value=template.data_extraction_goal)
                
                with st.expander("Advanced Settings"):
                    edited_advanced_settings = template.advanced_settings.copy()
                    edited_advanced_settings['custom_field'] = st.text_input("Custom Field", value=template.advanced_settings.get('custom_field', ''))

                save_edits = st.form_submit_button("Save Changes")
                
                if save_edits:
                    template.name = edited_name
                    template.url = edited_url
                    template.navigation_goal = edited_navigation_goal
                    template.data_extraction_goal = edited_data_extraction_goal
                    template.advanced_settings = edited_advanced_settings
                    save_templates(st.session_state.templates)
                    st.success("Template updated successfully!")
                    del st.session_state.edit_template
                    st.rerun()

    # Handle use template
    if 'use_template' in st.session_state:
        template = next((t for t in st.session_state.templates if t.id == st.session_state.use_template), None)
        if template:
            st.success(f"Using template: {template.name}")
            # Add your logic here to use the template
            del st.session_state.use_template


if __name__ == "__main__":
    templates_page()

================
File: templates.json
================
[
  {
    "id": "8ba306f8-8aa3-4567-9d73-de66b5998615",
    "name": "Nmap scan",
    "url": "192.168.1.63",
    "navigation_goal": "identify and scan the ports on my machine",
    "data_extraction_goal": "open ports ",
    "advanced_settings": {
      "custom_field": ""
    }
  },
  {
    "id": "6c0ade2b-89df-447a-bdcc-16b4475a1d11",
    "name": "WAF",
    "url": "192.168.1.63",
    "navigation_goal": "identify and analyze my network",
    "data_extraction_goal": "important details from my network",
    "advanced_settings": {
      "custom_field": ""
    }
  }
]

================
File: timed_input.py
================
from inputimeout import inputimeout, TimeoutOccurred

def timeout_input(prompt, timeout=10):
    try:
        import readline
        user_input = inputimeout(prompt=prompt, timeout=timeout)
        return user_input
    except TimeoutOccurred:
        return ""

================
File: tool.py
================
from abc import abstractmethod
from typing import TypedDict
from agent import Agent
from python.helpers.print_style import PrintStyle
from python.helpers import files, messages

class Response:
    def __init__(self, message: str, break_loop: bool) -> None:
        self.message = message
        self.break_loop = break_loop
    
class Tool:

    def __init__(self, agent: Agent, name: str, args: dict[str,str], message: str, **kwargs) -> None:
        self.agent = agent
        self.name = name
        self.args = args
        self.message = message

    @abstractmethod
    def execute(self,**kwargs) -> Response:
        pass

    def before_execution(self, **kwargs):
        if self.agent.handle_intervention(): return # wait for intervention and handle it, if paused
        PrintStyle(font_color="#1B4F72", padding=True, background_color="white", bold=True).print(f"{self.agent.agent_name}: Using tool '{self.name}':")
        if self.args and isinstance(self.args, dict):
            for key, value in self.args.items():
                PrintStyle(font_color="#85C1E9", bold=True).stream(self.nice_key(key)+": ")
                PrintStyle(font_color="#85C1E9", padding=isinstance(value,str) and "\n" in value).stream(value)
                PrintStyle().print()
                    
    def after_execution(self, response: Response, **kwargs):
        text = messages.truncate_text(response.message.strip(), self.agent.config.max_tool_response_length)
        msg_response = files.read_file("./prompts/fw.tool_response.md", tool_name=self.name, tool_response=text)
        if self.agent.handle_intervention(): return # wait for intervention and handle it, if paused
        self.agent.append_message(msg_response, human=True)
        PrintStyle(font_color="#1B4F72", background_color="white", padding=True, bold=True).print(f"{self.agent.agent_name}: Response from tool '{self.name}':")
        PrintStyle(font_color="#85C1E9").print(response.message)

    def nice_key(self, key:str):
        words = key.split('_')
        words = [words[0].capitalize()] + [word.lower() for word in words[1:]]
        result = ' '.join(words)
        return result

================
File: vdb.py
================
from langchain.storage import InMemoryByteStore, LocalFileStore
from langchain.embeddings import CacheBackedEmbeddings
from langchain_core.embeddings import Embeddings

from langchain_chroma import Chroma
import chromadb
from chromadb.config import Settings

from . import files
from langchain_core.documents import Document
import uuid


class VectorDB:

    def __init__(self, embeddings_model:Embeddings, in_memory=False, cache_dir="./cache"):
        print("Initializing VectorDB...")
        self.embeddings_model = embeddings_model

        db_cache = files.get_abs_path(cache_dir,"database")

        self.client =chromadb.PersistentClient(path=db_cache)
        self.collection = self.client.create_collection("my_collection")
        self.collection

        
    def search(self, query:str, results=2):
        emb = self.embeddings_model.embed_query(query)
        res = self.collection.query(query_embeddings=[emb],n_results=results)
        best = res["documents"][0][0] # type: ignore
        
    # def delete_documents(self, query):
    #     score_limit = 1
    #     k = 2
    #     tot = 0
    #     while True:
    #         # Perform similarity search with score
    #         docs = self.db.similarity_search_with_score(query, k=k)

    #         # Extract document IDs and filter based on score
    #         document_ids = [result[0].metadata["id"] for result in docs if result[1] < score_limit]

    #         # Delete documents with IDs over the threshold score
    #         if document_ids:
    #             fnd = self.db.get(where={"id": {"$in": document_ids}})
    #             if fnd["ids"]: self.db.delete(ids=fnd["ids"])
    #             tot += len(fnd["ids"])
            
    #         # If fewer than K document IDs, break the loop
    #         if len(document_ids) < k:
    #             break
        
    #     return tot

    def insert(self, data:str):
        
        id = str(uuid.uuid4())
        emb = self.embeddings_model.embed_documents([data])[0]

        self.collection.add(
            ids=[id],
            embeddings=[emb],
            documents=[data],
            )

        return id

================
File: vector_db.py
================
from langchain.storage import InMemoryByteStore, LocalFileStore
from langchain.embeddings import CacheBackedEmbeddings
from langchain_chroma import Chroma

from . import files
from langchain_core.documents import Document
import uuid


class VectorDB:

    def __init__(self, embeddings_model, in_memory=False, cache_dir="./cache"):
        print("Initializing VectorDB...")
        self.embeddings_model = embeddings_model

        em_cache = files.get_abs_path(cache_dir,"embeddings")
        db_cache = files.get_abs_path(cache_dir,"database")
        
        if in_memory:
            self.store = InMemoryByteStore()
        else:
            self.store = LocalFileStore(em_cache)


        #here we setup the embeddings model with the chosen cache storage
        self.embedder = CacheBackedEmbeddings.from_bytes_store(
            embeddings_model, 
            self.store, 
            namespace=getattr(embeddings_model, 'model', getattr(embeddings_model, 'model_name', "default")) )


        self.db = Chroma(embedding_function=self.embedder,persist_directory=db_cache)
        
        
    def search_similarity(self, query, results=3):
        return self.db.similarity_search(query,results)
    
    def search_similarity_threshold(self, query, results=3, threshold=0.5):
        return self.db.search(query, search_type="similarity_score_threshold", k=results, score_threshold=threshold)

    def search_max_rel(self, query, results=3):
        return self.db.max_marginal_relevance_search(query,results)

    def delete_documents_by_query(self, query:str, threshold=0.1):
        k = 100
        tot = 0
        while True:
            # Perform similarity search with score
            docs = self.search_similarity_threshold(query, results=k, threshold=threshold)

            # Extract document IDs and filter based on score
            # document_ids = [result[0].metadata["id"] for result in docs if result[1] < score_limit]
            document_ids = [result.metadata["id"] for result in docs]
            

            # Delete documents with IDs over the threshold score
            if document_ids:
                # fnd = self.db.get(where={"id": {"$in": document_ids}})
                # if fnd["ids"]: self.db.delete(ids=fnd["ids"])
                # tot += len(fnd["ids"])
                self.db.delete(ids=document_ids)
                tot += len(document_ids)
                                    
            # If fewer than K document IDs, break the loop
            if len(document_ids) < k:
                break
        
        return tot

    def delete_documents_by_ids(self, ids:list[str]):
        # pre = self.db.get(ids=ids)["ids"]
        self.db.delete(ids=ids)
        # post = self.db.get(ids=ids)["ids"]
        #TODO? compare pre and post
        return len(ids)
        
    def insert_document(self, data):
        id = str(uuid.uuid4())
        self.db.add_documents(documents=[ Document(data, metadata={"id": id}) ], ids=[id])
        
        return id
